{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "543f788a-1a1c-4390-ae10-5e9bc6a3c823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "from scipy.stats import norm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torch.nn.functional as F\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import math\n",
    "from argparse import Namespace\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import os  \n",
    "from joblib import Parallel, delayed\n",
    "#sys.path.append(\"/home/yuedu/deep-my\")\n",
    "# sys.path.append(\"/work/home/ac7hjj2nfu/project/indtest\")\n",
    "#sys.path.append(\"C:\\\\Users\\\\duyue\\\\.spyder-py3\")\n",
    "\n",
    "\n",
    "#from fun_all import generate_one_minus_one_distribution\n",
    "\n",
    "import itertools\n",
    "import time \n",
    "import fun_all\n",
    "import gene_data_Copy1\n",
    "import non_connect_nn_l1\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc68569c-1279-43dc-9f82-829e78a10434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "import smtplib\n",
    "import email.utils\n",
    "from email.mime.text import MIMEText\n",
    "def send_email(subject, content):\n",
    "    message = MIMEText(content)\n",
    "    message['To'] = email.utils.formataddr(('Duuuuu', '3013081232@qq.com'))\n",
    "    message['From'] = email.utils.formataddr(('Duuuuu', '3013081232@qq.com'))\n",
    "    message['Subject'] = subject\n",
    "    server = smtplib.SMTP_SSL('smtp.qq.com', 465)\n",
    "    server.login('3013081232@qq.com', 'ysvbwhdzhtkzdfcc')\n",
    "    try:\n",
    "        server.sendmail('3013081232@qq.com', ['3013081232@qq.com'], msg=message.as_string())\n",
    "        server.quit()\n",
    "        print(\"邮件发送成功\")\n",
    "    except Exception as e:\n",
    "        print(\"邮件发送失败:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96aa88b6-4670-4a20-8457-a327ce6e6594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "def init_logging(log_file):\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "    \n",
    "    # 文件处理器\n",
    "    file_handler = logging.FileHandler(log_file, mode='a', encoding='utf-8')\n",
    "    file_handler.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "    file_handler.setFormatter(formatter)\n",
    "    \n",
    "    # 控制台处理器\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(logging.INFO)\n",
    "    console_handler.setFormatter(formatter)\n",
    "    \n",
    "    # 添加处理器\n",
    "    if not logger.handlers:\n",
    "        logger.addHandler(file_handler)\n",
    "        logger.addHandler(console_handler)\n",
    "    \n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46007fd2-3b73-4653-bcc7-08108ee78bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(mat, thresh):\n",
    "    mat = torch.clamp(mat, min=-thresh, max=thresh)\n",
    "    return mat\n",
    "def trainer(i,kk,exp_v, res_v, n_1, n_2, batchsize, val_pct, lr, n_epochs, patience, input_features, hidden_features1, hidden_features2, output_features, device, thresh=None, plot=False):\n",
    "    logger = init_logging(\"logex6_nn.log\")  # 为每个任务初始化日志\n",
    "    criterion = nn.MSELoss()\n",
    "    model = non_connect_nn_l1.AdaptiveNet(input_features, hidden_features1, hidden_features2, output_features).to(device)\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                   lr=lr,\n",
    "                                   weight_decay=0.)\n",
    "    # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, \n",
    "    #                                           step_size=20,\n",
    "    #                                           gamma=0.9)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5, min_lr=1e-4)\n",
    "    # 定义优化器，这里使用Adam优化器\n",
    "\n",
    "    #dataset = TensorDataset(exp_v[n_1:(n_1+n_2),:], res_v[n_1:(n_1+n_2)])\n",
    "    train_dataset = TensorDataset(exp_v[n_1:(n_1+n_2),:], res_v[n_1:(n_1+n_2)])\n",
    "    \n",
    "    n1_ind = torch.arange(0, n_1)\n",
    "    n2_ind = torch.arange(n_1+n_2, n)\n",
    "    all_indices = torch.cat([n1_ind, n2_ind])\n",
    "    val_dataset = TensorDataset(exp_v[all_indices,:], res_v[all_indices])\n",
    "    # val_size = int(val_pct * len(dataset))\n",
    "    # train_size = len(dataset) - val_size\n",
    "    # train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True,drop_last=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batchsize, shuffle=False)\n",
    "    run_loss = 0 \n",
    "    \n",
    "    min_val_loss = float('inf')  # 保存最小验证损失\n",
    "    no_improvement_epochs = 0  # 记录验证损失未改善的次数\n",
    "    \n",
    "    val_losses = [] \n",
    "    run_losses = []\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        run_loss1=run_loss\n",
    "        run_loss = 0\n",
    "    \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.view(-1), labels)\n",
    "            # print(outputs.squeeze().shape, labels.shape)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            run_loss += loss.item()\n",
    "    \n",
    "        run_loss =  run_loss / len(train_loader)\n",
    "        run_losses.append(run_loss)\n",
    "        #print(f\"the {epoch+1}, TRAIN loss {run_loss}\")\n",
    "    \n",
    "         #验证\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_labels in val_loader:\n",
    "                val_inputs = val_inputs.to(device)\n",
    "                val_labels = val_labels.to(device)\n",
    "    \n",
    "                val_outputs = model(val_inputs)\n",
    "                val_loss += criterion(val_outputs.view(-1), val_labels).item()\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < min_val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            no_improvement_epochs = 0  # 重置\n",
    "            best_model_state = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "            # torch.save(model_all.state_dict(), 'best_model.pth')  # 保存最佳模型\n",
    "        else:\n",
    "            no_improvement_epochs += 1\n",
    "\n",
    "        if no_improvement_epochs >= patience or min_val_loss<1e-3:\n",
    "            #print(f\"Early stopping at epoch {epoch + 1}, validation loss did not improve for {patience} epochs. {min_val_loss}\")\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(best_model_state)\n",
    "    if thresh:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            fit = threshold(model.forward(exp_v.to(device)),thresh)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            fit = model(exp_v.to(device))\n",
    "    error = res_v.to(device) - fit.squeeze()\n",
    "    if i % 100 == 0 and kk%100==0:\n",
    "        logger.info(f\"第{kk}次的{i}网络完成\")  # 写入日志\n",
    "    if plot:\n",
    "        fig = plt.figure(figsize=(10, 4))\n",
    "        plt.style.use('fivethirtyeight')\n",
    "        plt.plot(run_losses,\n",
    "                 label='Training Loss', color='C0', linewidth=2)\n",
    "        plt.plot(val_losses,\n",
    "                 label='Validation Loss', color='C1', linewidth=2)\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return {'model': model,\n",
    "                'error': error,\n",
    "                'losses': run_losses,\n",
    "                'val_losses': val_losses,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "339a50da-a1e0-4bf0-afb1-4f947d88246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_fun(kk,x, y, z, n, n_1, n_2, n_3, n_tilde, p, q, m, dep, alpha,batchsize,val_pct,lr,n_epochs, patience, input_features, hidden_features1, hidden_features2, output_features, device):\n",
    "    x = fun_all.data_transform(x[0:n_1,:], x)\n",
    "    y = fun_all.data_transform(y[0:n_1,:], y)\n",
    "    z = fun_all.data_transform(z[0:n_1,:], z)\n",
    "    sA = torch.zeros(3, 3)\n",
    "    rep_xy = torch.cat([x, y], dim=1)\n",
    "    thresh = (math.log(m*n))**(1/2) * math.log(n)\n",
    "    results = [trainer(i,kk,z, rep_xy[:, i], n_1, n_2, batchsize, val_pct, lr, n_epochs, patience, \n",
    "                       input_features, hidden_features1, hidden_features2, output_features, device,thresh) for i in range(p + q)]\n",
    "    \n",
    "    error_all = torch.stack([res['error'] for res in results],dim=1)\n",
    "    eps_all = error_all[:, 0:p]\n",
    "    delta_all = error_all[:, p:(p+q)]\n",
    "    \n",
    "    ell = n_tilde.shape[0]\n",
    "    N=5000\n",
    "    N_1 = 300\n",
    "    res1_red = torch.zeros(N_1, ell)\n",
    "    res1_norm = torch.zeros(N_1, ell)\n",
    "    res1_mm = torch.zeros(N_1, ell)\n",
    "    ########data driven\n",
    "    for t in range(N_1):\n",
    "        # torch.manual_seed((t+1)*54321)\n",
    "        f1 = (torch.randn(n, n) / (n**(1/2))).to(device)\n",
    "        f2 = (torch.randn(n, n) / (n**(1/2))).to(device)\n",
    "        f3 = (torch.randn(n, n) / (n**(1/2))).to(device)\n",
    "        w_hs_norm = f1 @ z.to(device)\n",
    "        eps_norm = f2 @ eps_all\n",
    "        delta_norm = f3 @ delta_all\n",
    "        with torch.no_grad():\n",
    "            f_h_hs = torch.stack([res['model'].forward(w_hs_norm.to(device)).squeeze() for res in results],dim=1)\n",
    "        thresh1 = norm.ppf((1-1/n_1), 0, 1)\n",
    "        w_hs_norm  = threshold(w_hs_norm, thresh1)\n",
    "        u_hs_norm = f_h_hs[:, 0: p] + eps_norm\n",
    "        u_hs_norm = threshold(u_hs_norm, thresh1)\n",
    "        v_hs_norm = f_h_hs[:, p: (p+q)] + delta_norm\n",
    "        v_hs_norm = threshold(v_hs_norm, thresh1)\n",
    "        if t==0:\n",
    "            rep_uv = torch.cat([u_hs_norm, v_hs_norm], dim=1)\n",
    "            results2 = [trainer(k,t,w_hs_norm, rep_uv[:, k], n_1, n_2, batchsize, val_pct, lr, n_epochs, patience, input_features, hidden_features1, hidden_features2, output_features, device,thresh) for k in range(p + q)]\n",
    "        ###内部训练神经网络\n",
    "        with torch.no_grad():\n",
    "            f_hhm = torch.stack([res['model'].forward(w_hs_norm.to(device)).squeeze() for res in results2],dim=1)\n",
    "        error_all_u = torch.cat([u_hs_norm, v_hs_norm], dim=1) - f_hhm\n",
    "        eps_hhs = error_all_u[(n_1+n_2):n, 0:p]\n",
    "        delta_hhs = error_all_u[(n_1+n_2):n, p:(p+q)]    \n",
    "        M = fun_all.generate_one_minus_one_distribution(N, n_3).float().to(device)\n",
    "        M_norm = torch.randn(N, n_3).to(device) \n",
    "        M_mm = fun_all.generate_mammen(N,n_3).float().to(device)\n",
    "        for i in range(ell):\n",
    "            ###critical value\n",
    "            n_tilde1 = n_tilde[i]\n",
    "            sqrt_n_tilde1 = torch.sqrt(torch.as_tensor(n_tilde1)).to(device)\n",
    "            dat_new = torch.empty(N, p).to(device)\n",
    "            dat_new_n = torch.empty(N, p).to(device)\n",
    "            dat_new_mm = torch.empty(N, p).to(device)\n",
    "            for j in range(p):\n",
    "                Ai = eps_hhs[0:n_tilde1, j:j+1]\n",
    "                dat_i = Ai * delta_hhs[0:n_tilde1, :]  # Hadamard 内积，形状 (n_tilde1, q)\n",
    "                dat_i = dat_i - torch.mean(dat_i, dim=0, keepdim=True)  # 减去均值\n",
    "                result_i = torch.max(abs(M[:, 0:n_tilde1] @ dat_i / sqrt_n_tilde1), axis=1)[0]  # 形状 (N,)\n",
    "                dat_new[:, j] = result_i  # 存储结果\n",
    "                result_i_n = torch.max(abs(M_norm[:, 0:n_tilde1] @ dat_i / sqrt_n_tilde1), axis=1)[0]  # 形状 (N,)\n",
    "                dat_new_n[:, j] = result_i_n  # 存储结果\n",
    "                result_i_mm = torch.max(abs(M_mm[:, 0:n_tilde1] @ dat_i / sqrt_n_tilde1), axis=1)[0]  # 形状 (N,)\n",
    "                dat_new_mm[:, j] = result_i_mm  # 存储结果\n",
    "            dat_new = torch.max(dat_new, axis = 1).values\n",
    "            dat_new_n = torch.max(dat_new_n, axis = 1).values\n",
    "            dat_new_mm = torch.max(dat_new_mm, axis = 1).values\n",
    "            # dat = torch.einsum('np,nq->npq', eps_hhs[0:n_tilde1, :], delta_hhs[0:n_tilde1, :]).reshape(n_tilde1, -1)  # (n_tilde1, p * q)\n",
    "            # # dat = eps_hhs[0:n_tilde1, :].repeat_interleave(q, dim=1) * delta_hhs[0:n_tilde1, :].repeat(1, p)\n",
    "            # dat = dat - torch.mean(dat, dim=0)\n",
    "            # #rademacher \n",
    "            # dat_new = torch.max(abs(M[:,0:n_tilde1].float() @ dat / np.sqrt(n_tilde1)), axis=1)[0]\n",
    "            cv_red = torch.kthvalue(dat_new, (N-int(N*alpha)+1)).values\n",
    "                #norm\n",
    "            # dat_new_n = torch.max(abs(M_norm[:,0:n_tilde1] @ dat / np.sqrt(n_tilde1)), axis=1)[0]\n",
    "            cv_norm = torch.kthvalue(dat_new_n, (N-int(N*alpha)+1)).values\n",
    "            #norm\n",
    "            # dat_new_mm = torch.max(abs(M_mm[:,0:n_tilde1].float() @ dat / np.sqrt(n_tilde1)), axis=1)[0]\n",
    "            cv_mm = torch.kthvalue(dat_new_mm, (N-int(N*alpha)+1)).values\n",
    "            #test-statistics\n",
    "            test1 = np.sqrt(n_tilde1) * torch.max(abs(eps_hhs[0:n_tilde1, :].T @ delta_hhs[0:n_tilde1, :] / n_tilde1))\n",
    "            res1_red[t, i]  = test1 >cv_red\n",
    "            res1_norm[t, i] = test1 >cv_norm\n",
    "            res1_mm[t, i]   = test1 >cv_mm\n",
    "            #if t == 0 and i == 0:\n",
    "                #print(test1, cv_red, cv_norm, cv_mm)\n",
    "        #print(t)\n",
    "    et = time.time()\n",
    "    # print(et-st)     \n",
    "    ##########\n",
    "\n",
    "    #st2 =time.time()            \n",
    "    N=5000\n",
    "    n_s = n_1 + n_2\n",
    "    ####red       \n",
    "    size_red  = torch.mean(res1_red, dim=0) \n",
    "    \n",
    "    index_red = int(max(torch.where(abs(size_red-alpha) == min(abs(size_red-alpha)))[0]))\n",
    "    #index_red = torch.argmin(abs(size_red - alpha)).item()\n",
    "    n_tilde_red = int(n_tilde[index_red])\n",
    "    M = fun_all.generate_one_minus_one_distribution(N, n_tilde_red).float().to(device)\n",
    "    eps_t1 = eps_all[n_s:(n_s+n_tilde_red), :]\n",
    "    delta_t1 = delta_all[n_s:(n_s+n_tilde_red), :]\n",
    "    test_1 = torch.max(abs(eps_t1.T @ delta_t1 / np.sqrt(n_tilde_red) ))\n",
    "    #############\n",
    "    \n",
    "    \n",
    "    size_norm  = torch.mean(res1_norm, dim=0) \n",
    "    index_norm = int(max(torch.where(abs(size_norm-alpha) == min(abs(size_norm-alpha)))[0]))\n",
    "    #index_norm = torch.argmin(abs(size_norm - alpha)).item()\n",
    "    n_tilde_norm = int(n_tilde[index_norm])\n",
    "    eps_t2 = eps_all[n_s:(n_s+n_tilde_norm), :]\n",
    "    delta_t2 = delta_all[n_s:(n_s+n_tilde_norm), :]\n",
    "    test_2 =  torch.max(abs(eps_t2.T @ delta_t2 / np.sqrt(n_tilde_norm) ))\n",
    "    M_norm = torch.randn(N, n_tilde_norm).to(device)\n",
    "    #norm \n",
    "\n",
    "    ####mannen       \n",
    "    size_mm  = torch.mean(res1_mm, dim=0) \n",
    "    index_mm = int(max(torch.where(abs(size_mm-alpha) == min(abs(size_mm-alpha)))[0]))\n",
    "    #index_mm = torch.argmin(abs(size_mm - alpha)).item()\n",
    "    n_tilde_mm = int(n_tilde[index_mm])\n",
    "    eps_t3 = eps_all[n_s:(n_s+n_tilde_mm), :]\n",
    "    delta_t3 = delta_all[n_s:(n_s+n_tilde_mm), :]\n",
    "    test_3 = torch.max(abs(eps_t3.T @ delta_t3 / np.sqrt(n_tilde_mm) ))\n",
    "    M_mm = fun_all.generate_mammen(N,n_tilde_mm).float().to(device)\n",
    "    \n",
    "    \n",
    "    n_tilde_red = torch.sqrt(torch.as_tensor(n_tilde_red)).to(device)\n",
    "    n_tilde_norm = torch.sqrt(torch.as_tensor(n_tilde_norm)).to(device)\n",
    "    n_tilde_mm = torch.sqrt(torch.as_tensor(n_tilde_mm)).to(device)\n",
    "    dat_new1 = torch.empty(N, p).to(device)\n",
    "    dat_new2 = torch.empty(N, p).to(device)\n",
    "    dat_new3 = torch.empty(N, p).to(device)\n",
    "    for i in range(p):\n",
    "        dat_1 = eps_t1[:, i:i+1] * delta_t1  # Hadamard 内积，形状 (n_tilde1, q)\n",
    "        dat_1 = dat_1 - torch.mean(dat_1, dim=0, keepdim=True)  # 减去均值\n",
    "        dat_new1[:, i] = torch.max(abs(M @ dat_1 / n_tilde_red), axis=1)[0]  # 形状 (N,)\n",
    "\n",
    "        dat_2 = eps_t2[:, i:i+1] * delta_t2  # Hadamard 内积，形状 (n_tilde1, q)\n",
    "        dat_2 = dat_2 - torch.mean(dat_2, dim=0, keepdim=True)  # 减去均值\n",
    "        dat_new2[:, i] = torch.max(abs(M_norm @ dat_2 / n_tilde_norm), axis=1)[0]  # 形状 (N,)\n",
    "        \n",
    "        dat_3 = eps_t3[:, i:i+1] * delta_t3  # Hadamard 内积，形状 (n_tilde1, q)\n",
    "        dat_3 = dat_3 - torch.mean(dat_3, dim=0, keepdim=True)  # 减去均值\n",
    "        dat_new3[:, i] = torch.max(abs(M_mm @ dat_3 / n_tilde_mm), axis=1)[0]  # 形状 (N,)\n",
    "    # dat_1 = eps_t1.repeat_interleave(q, dim=1) * delta_t1.repeat(1, p)\n",
    "    # dat_1 = dat_1 - torch.mean(dat_1, dim=0)\n",
    "    #rademacher\n",
    "    \n",
    "    dat_new1 = torch.max(dat_new1, axis = 1).values\n",
    "    dat_new2 = torch.max(dat_new2, axis = 1).values\n",
    "    dat_new3 = torch.max(dat_new3, axis = 1).values\n",
    "    # dat_new1 = torch.max(abs(M @ dat_1 / np.sqrt(n_tilde_red)), axis=1)[0]\n",
    "    cv_red = torch.kthvalue(dat_new1, (N-int(N*alpha)+1)).values\n",
    "    sA[0,0] = (test_1 > cv_red)\n",
    "    sA[0,1] = size_red[index_red] \n",
    "    sA[0,2]= n_tilde[index_red]\n",
    "    \n",
    "    \n",
    "    #st1 =time.time()\n",
    "    \n",
    "    #############\n",
    "    # dat_2 = eps_t2.repeat_interleave(q, dim=1) * delta_t2.repeat(1, p)\n",
    "    # dat_2 = dat_2 - torch.mean(dat_2, dim=0)\n",
    "    # dat_new2 = torch.max(abs(M_norm @ dat_2 / np.sqrt(n_tilde_norm)), axis=1)[0]\n",
    "    cv_norm = torch.kthvalue(dat_new2, (N-int(N*alpha)+1)).values\n",
    "    #et1 =time.time()\n",
    "    #print(et1-st1)\n",
    "    sA[1,0] = (test_2 > cv_norm)\n",
    "    sA[1,1] = size_norm[index_norm] \n",
    "    sA[1,2]= n_tilde[index_norm]\n",
    "     \n",
    "    \n",
    "    \n",
    "    #############\n",
    "    # dat_3 = eps_t3.repeat_interleave(q, dim=1) * delta_t3.repeat(1, p)\n",
    "    # dat_3 = dat_3 - torch.mean(dat_3, dim=0)\n",
    "    # #norm \n",
    "    \n",
    "    # dat_new3 = torch.max(abs(M_mm @ dat_3 / np.sqrt(n_tilde_mm)), axis=1)[0]\n",
    "    cv_mm = torch.kthvalue(dat_new3, (N-int(N*alpha)+1)).values\n",
    "    sA[2,0] = (test_3 > cv_mm)\n",
    "    sA[2,1] = size_norm[index_mm] \n",
    "    sA[2,2]= n_tilde[index_mm]    \n",
    "    \n",
    "    #et2 =time.time()\n",
    "    #print(et2-st2)\n",
    "    \n",
    "    return  sA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e308795-b12b-47b1-a163-48e750e2199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    lr = 0.01,\n",
    "    device = 'cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b5062e0-8fb3-4dea-8577-3dccdbb144c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=400 \n",
    "q=400 \n",
    "m=5 \n",
    "n = 200 \n",
    "n_1 = int(n/3)\n",
    "n_2 = int(n/2)\n",
    "n_3 = n - n_1 -n_2\n",
    "\n",
    "######n50\n",
    "n_tilde = torch.arange(int(n_3/3), n_3, 2)\n",
    "alpha=0.05\n",
    "\n",
    "\n",
    "n_my = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bace8485-4246-4ac9-989a-468f0e73d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化网络\n",
    "input_features = m\n",
    "hidden_features1 = int(128)\n",
    "hidden_features2 = int(32)\n",
    "output_features = 1\n",
    "n_epochs = 400\n",
    "patience = 30\n",
    "batchsize = 16\n",
    "val_pct = 0.15\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c773688f-e50d-46d7-b277-9784db892397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(i, n, p, q, m, dep, n_1, n_2, n_3, n_tilde, alpha, gene_data, para_time):\n",
    "    logger = init_logging(\"logex6_n200_p400_12.log\")  # 为每个任务初始化日志\n",
    "    torch.manual_seed((i + 1) * 12345)  # 设置随机种子\n",
    "    data_my = gene_data(n, p, q, m, dep)  # 生成数据\n",
    "    \n",
    "    tasks_per_machine = para_time // 8\n",
    "    tmp = tasks_per_machine * 8 \n",
    "    adjusted_index = (i - tmp if i > (tmp-1) else i) // tasks_per_machine\n",
    "    machine_index = adjusted_index % 8\n",
    "    device = args.device+':'+str(machine_index)\n",
    "    \n",
    "    x = data_my[\"x\"] \n",
    "    y = data_my[\"y\"] \n",
    "    z = data_my[\"z\"] \n",
    "    # z = torch.randn(n,p)\n",
    "    # x = torch.exp(- z**2/2)* torch.sin(2*z) +  torch.randn(n,p)  \n",
    "    # y = torch.exp(- z**2/2)* torch.sin(2*z) +  torch.randn(n,p)  #+x\n",
    "    logger.info(f\"任务 {i} 完成\")  # 写入日志\n",
    "    result = gauss_fun(i,x, y, z, n, n_1, n_2, n_3, n_tilde, p, q, m, dep, alpha,batchsize,val_pct,lr,n_epochs, patience, input_features, hidden_features1, hidden_features2, output_features, device)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccd3544-d218-4ff6-8c3c-4583c891702b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_data_ex6 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76dce9ba42c4cf1a9903e479f0d0ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-23 03:38:21,700 - 任务 8 完成\n",
      "2025-01-23 03:38:21,761 - 任务 14 完成\n",
      "2025-01-23 03:38:21,765 - 任务 13 完成\n",
      "2025-01-23 03:38:21,783 - 任务 10 完成\n",
      "2025-01-23 03:38:21,785 - 任务 22 完成\n",
      "2025-01-23 03:38:21,794 - 任务 2 完成\n",
      "2025-01-23 03:38:21,797 - 任务 16 完成\n",
      "2025-01-23 03:38:21,821 - 任务 18 完成\n",
      "2025-01-23 03:38:21,832 - 任务 21 完成\n",
      "2025-01-23 03:38:21,894 - 任务 24 完成\n",
      "2025-01-23 03:38:22,014 - 任务 55 完成\n",
      "2025-01-23 03:38:22,067 - 任务 56 完成\n",
      "2025-01-23 03:38:22,087 - 任务 47 完成\n",
      "2025-01-23 03:38:22,101 - 任务 61 完成\n",
      "2025-01-23 03:38:22,136 - 任务 71 完成\n",
      "2025-01-23 03:38:22,140 - 任务 4 完成\n",
      "2025-01-23 03:38:22,209 - 任务 1 完成\n",
      "2025-01-23 03:38:22,244 - 任务 76 完成\n",
      "2025-01-23 03:38:22,251 - 任务 6 完成\n",
      "2025-01-23 03:38:22,267 - 任务 3 完成\n",
      "2025-01-23 03:38:22,270 - 任务 0 完成\n",
      "2025-01-23 03:38:22,274 - 任务 9 完成\n",
      "2025-01-23 03:38:22,286 - 任务 69 完成\n",
      "2025-01-23 03:38:22,307 - 任务 70 完成\n",
      "2025-01-23 03:38:22,310 - 任务 75 完成\n",
      "2025-01-23 03:38:22,314 - 任务 74 完成\n",
      "2025-01-23 03:38:22,333 - 任务 72 完成\n",
      "2025-01-23 03:38:22,333 - 任务 12 完成\n",
      "2025-01-23 03:38:22,344 - 任务 15 完成\n",
      "2025-01-23 03:38:22,354 - 任务 5 完成\n",
      "2025-01-23 03:38:22,374 - 任务 7 完成\n",
      "2025-01-23 03:38:22,435 - 任务 77 完成\n",
      "2025-01-23 03:38:22,441 - 任务 11 完成\n",
      "2025-01-23 03:38:22,447 - 任务 85 完成\n",
      "2025-01-23 03:38:22,453 - 任务 66 完成\n",
      "2025-01-23 03:38:22,458 - 任务 27 完成\n",
      "2025-01-23 03:38:22,464 - 任务 81 完成\n",
      "2025-01-23 03:38:22,465 - 任务 20 完成\n",
      "2025-01-23 03:38:22,467 - 任务 17 完成\n",
      "2025-01-23 03:38:22,479 - 任务 35 完成\n",
      "2025-01-23 03:38:22,497 - 任务 43 完成\n",
      "2025-01-23 03:38:22,508 - 任务 31 完成\n",
      "2025-01-23 03:38:22,512 - 任务 51 完成\n",
      "2025-01-23 03:38:22,515 - 任务 46 完成\n",
      "2025-01-23 03:38:22,521 - 任务 90 完成\n",
      "2025-01-23 03:38:22,532 - 任务 23 完成\n",
      "2025-01-23 03:38:22,535 - 任务 34 完成\n",
      "2025-01-23 03:38:22,541 - 任务 40 完成\n",
      "2025-01-23 03:38:22,542 - 任务 87 完成\n",
      "2025-01-23 03:38:22,555 - 任务 37 完成\n",
      "2025-01-23 03:38:22,561 - 任务 38 完成\n",
      "2025-01-23 03:38:22,571 - 任务 29 完成\n",
      "2025-01-23 03:38:22,572 - 任务 33 完成\n",
      "2025-01-23 03:38:22,576 - 任务 48 完成\n",
      "2025-01-23 03:38:22,581 - 任务 44 完成\n",
      "2025-01-23 03:38:22,589 - 任务 45 完成\n",
      "2025-01-23 03:38:22,602 - 任务 26 完成\n",
      "2025-01-23 03:38:22,605 - 任务 28 完成\n",
      "2025-01-23 03:38:22,621 - 任务 68 完成\n",
      "2025-01-23 03:38:22,623 - 任务 52 完成\n",
      "2025-01-23 03:38:22,624 - 任务 58 完成\n",
      "2025-01-23 03:38:22,645 - 任务 19 完成\n",
      "2025-01-23 03:38:22,650 - 任务 32 完成\n",
      "2025-01-23 03:38:22,664 - 任务 99 完成\n",
      "2025-01-23 03:38:22,665 - 任务 30 完成\n",
      "2025-01-23 03:38:22,686 - 任务 49 完成\n",
      "2025-01-23 03:38:22,704 - 任务 39 完成\n",
      "2025-01-23 03:38:22,715 - 任务 67 完成\n",
      "2025-01-23 03:38:22,719 - 任务 60 完成\n",
      "2025-01-23 03:38:22,722 - 任务 42 完成\n",
      "2025-01-23 03:38:22,728 - 任务 50 完成\n",
      "2025-01-23 03:38:22,729 - 任务 41 完成\n",
      "2025-01-23 03:38:22,733 - 任务 53 完成\n",
      "2025-01-23 03:38:22,740 - 任务 62 完成\n",
      "2025-01-23 03:38:22,742 - 任务 25 完成\n",
      "2025-01-23 03:38:22,743 - 任务 63 完成\n",
      "2025-01-23 03:38:22,760 - 任务 59 完成\n",
      "2025-01-23 03:38:22,764 - 任务 36 完成\n",
      "2025-01-23 03:38:22,765 - 任务 65 完成\n",
      "2025-01-23 03:38:22,770 - 任务 57 完成\n",
      "2025-01-23 03:38:22,777 - 任务 64 完成\n",
      "2025-01-23 03:38:22,789 - 任务 54 完成\n",
      "2025-01-23 03:38:22,805 - 任务 89 完成\n",
      "2025-01-23 03:38:22,809 - 任务 95 完成\n",
      "2025-01-23 03:38:22,914 - 任务 93 完成\n",
      "2025-01-23 03:38:22,917 - 任务 88 完成\n",
      "2025-01-23 03:38:22,942 - 任务 86 完成\n",
      "2025-01-23 03:38:22,946 - 任务 83 完成\n",
      "2025-01-23 03:38:22,959 - 任务 82 完成\n",
      "2025-01-23 03:38:22,961 - 任务 78 完成\n",
      "2025-01-23 03:38:22,974 - 任务 79 完成\n",
      "2025-01-23 03:38:22,978 - 任务 73 完成\n",
      "2025-01-23 03:38:22,997 - 任务 92 完成\n",
      "2025-01-23 03:38:23,028 - 任务 84 完成\n",
      "2025-01-23 03:38:23,080 - 任务 91 完成\n",
      "2025-01-23 03:38:23,084 - 任务 98 完成\n",
      "2025-01-23 03:38:23,119 - 任务 80 完成\n",
      "2025-01-23 03:38:23,122 - 任务 94 完成\n",
      "2025-01-23 03:38:23,135 - 任务 97 完成\n",
      "2025-01-23 03:38:23,161 - 任务 96 完成\n",
      "2025-01-23 03:38:44,597 - 第0次的0网络完成\n"
     ]
    }
   ],
   "source": [
    "cuda_cores = 100  # GPU 核心数量\n",
    "# cuda_cores = 100  # 可根据实际的 GPU 核心数量或 CPU 线程设置\n",
    "\n",
    "# sim_list = {'my_data_ex10':0}\n",
    "sim_list = {'my_data_ex6': 0,'my_data_ex7': 0,'my_data_ex8': 0,'my_data_ex9': 0,'my_data_ex10': 0}\n",
    "for sim, dep in sim_list.items():\n",
    "    resmy = torch.zeros(n_my, 3, 3)\n",
    "    print(sim, dep)\n",
    "    try:\n",
    "        with Parallel(n_jobs=cuda_cores) as parallel:\n",
    "            tmp_results = parallel(\n",
    "                delayed(run_simulation)(i, n, p, q, m, dep, n_1, n_2, n_3, n_tilde, alpha, getattr(gene_data_Copy1, sim), cuda_cores)\n",
    "                for i in tqdm(range(n_my))\n",
    "            )\n",
    "        results = torch.stack(tmp_results).to('cpu')\n",
    "        del tmp_results\n",
    "        \n",
    "\n",
    "        # results = torch.stack(Parallel(n_jobs=cuda_cores)(delayed(run_simulation)(i, n, p, q, m, dep, n_1, n_2, n_3, n_tilde, alpha, getattr(gene_data, sim), cuda_cores) for i in tqdm(range(n_my))))\n",
    "        res_all = torch.randn(n_my, 3)\n",
    "        res_size = torch.randn(n_my, 3)\n",
    "        res_n = torch.randn(n_my, 3)\n",
    "        for i in range(n_my):\n",
    "            res_all[i, :] = results[i, :, 0]\n",
    "            res_size[i, :] = results[i, :, 1]\n",
    "            res_n[i, :] = results[i, :, 2]\n",
    "            \n",
    "        res_my = torch.mean(res_all, dim=0)\n",
    "        \n",
    "        df1 = pd.DataFrame(res_my)\n",
    "    \n",
    "        dic_path = './ind1_test_m52'\n",
    "        file_path = os.path.join(dic_path, f'result_{sim}1.xlsx')\n",
    "        \n",
    "        # 将DataFrame保存到Excel文件\n",
    "        # df1.to_excel(file_path, index=False, sheet_name='Sheet1')\n",
    "\n",
    "        # 将 DataFrame 保存到 CSV 文件\n",
    "        file_path = os.path.join(dic_path, f'result_{sim}.csv')\n",
    "        df1.to_csv(file_path, index=False, encoding='utf-8')\n",
    "        \n",
    "        \n",
    "        df2 = pd.DataFrame(res_size)\n",
    "        # file_path2 = os.path.join(dic_path, f'result_{sim}power.xlsx')\n",
    "        file_path2 = os.path.join(dic_path, f'result_{sim}size.csv')\n",
    "        # 将DataFrame保存到Excel文件\n",
    "        # df2.to_excel(file_path2, index=False, sheet_name='Sheet1')\n",
    "        df2.to_csv(file_path2, index=False, encoding='utf-8')\n",
    "        \n",
    "        df3 = pd.DataFrame(res_n)\n",
    "        # file_path3 = os.path.join(dic_path, f'result_{sim}_n1.xlsx')\n",
    "        file_path3 = os.path.join(dic_path, f'result_{sim}_n.csv')\n",
    "        \n",
    "        # 将DataFrame保存到Excel文件\n",
    "        # df3.to_excel(file_path2, index=False, sheet_name='Sheet1')\n",
    "        df3.to_csv(file_path3, index=False, encoding='utf-8')\n",
    "        print(res_my)\n",
    "        send_email(f\"48号机{sim}的size程序运行成功\", str(res_my))\n",
    "\n",
    "        del results\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "    except Exception as e:\n",
    "        # 捕获异常并发送邮件\n",
    "        error_message = f\"程序运行出错:\\n{traceback.format_exc()}\"\n",
    "        print(error_message)\n",
    "        send_email(f\"48号机{sim}的size程序出错通知\", error_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2e7c03-160e-4557-b1f7-7575ea03230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_cores = 100  # GPU 核心数量\n",
    "# cuda_cores = 100  # 可根据实际的 GPU 核心数量或 CPU 线程设置\n",
    "\n",
    "# sim_list = {'my_data_ex7':int(5)}\n",
    "sim_list = {'my_data_ex6': int(p/10),'my_data_ex7': int(7),'my_data_ex8': int(p/10),'my_data_ex9': int(p/10),'my_data_ex10': int(p/10)}\n",
    "for sim, dep in sim_list.items():\n",
    "    resmy = torch.zeros(n_my, 3, 3)\n",
    "    print(sim, dep)\n",
    "    try:\n",
    "        with Parallel(n_jobs=cuda_cores) as parallel:\n",
    "            tmp_results = parallel(       \n",
    "                delayed(run_simulation)(i, n, p, q, m, dep, n_1, n_2, n_3, n_tilde, alpha, getattr(gene_data_Copy1, sim), cuda_cores)\n",
    "                for i in tqdm(range(n_my))\n",
    "            )\n",
    "        results = torch.stack(tmp_results).to('cpu')\n",
    "        del tmp_results\n",
    "        \n",
    "\n",
    "        # results = torch.stack(Parallel(n_jobs=cuda_cores)(delayed(run_simulation)(i, n, p, q, m, dep, n_1, n_2, n_3, n_tilde, alpha, getattr(gene_data, sim), cuda_cores) for i in tqdm(range(n_my))))\n",
    "        res_all = torch.randn(n_my, 3)\n",
    "        res_size = torch.randn(n_my, 3)\n",
    "        res_n = torch.randn(n_my, 3)\n",
    "        for i in range(n_my):\n",
    "            res_all[i, :] = results[i, :, 0]\n",
    "            res_size[i, :] = results[i, :, 1]\n",
    "            res_n[i, :] = results[i, :, 2]\n",
    "            \n",
    "        res_my = torch.mean(res_all, dim=0)\n",
    "        \n",
    "        df1 = pd.DataFrame(res_my)\n",
    "    \n",
    "        dic_path = './ind1_test_m52'\n",
    "        file_path = os.path.join(dic_path, f'result_{sim}1.xlsx')\n",
    "        \n",
    "        # 将DataFrame保存到Excel文件\n",
    "        # df1.to_excel(file_path, index=False, sheet_name='Sheet1')\n",
    "\n",
    "        # 将 DataFrame 保存到 CSV 文件\n",
    "        file_path = os.path.join(dic_path, f'result_{sim}1.csv')\n",
    "        df1.to_csv(file_path, index=False, encoding='utf-8')\n",
    "        \n",
    "        \n",
    "        df2 = pd.DataFrame(res_size)\n",
    "        # file_path2 = os.path.join(dic_path, f'result_{sim}power.xlsx')\n",
    "        file_path2 = os.path.join(dic_path, f'result_{sim}power.csv')\n",
    "        # 将DataFrame保存到Excel文件\n",
    "        # df2.to_excel(file_path2, index=False, sheet_name='Sheet1')\n",
    "        df2.to_csv(file_path2, index=False, encoding='utf-8')\n",
    "        \n",
    "        df3 = pd.DataFrame(res_n)\n",
    "        # file_path3 = os.path.join(dic_path, f'result_{sim}_n1.xlsx')\n",
    "        file_path3 = os.path.join(dic_path, f'result_{sim}_n1.csv')\n",
    "        \n",
    "        # 将DataFrame保存到Excel文件\n",
    "        # df3.to_excel(file_path2, index=False, sheet_name='Sheet1')\n",
    "        df3.to_csv(file_path3, index=False, encoding='utf-8')\n",
    "        print(res_my)\n",
    "        send_email(f\"48号机{sim}的power程序运行成功\", str(res_my))\n",
    "\n",
    "        del results\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "    except Exception as e:\n",
    "        # 捕获异常并发送邮件\n",
    "        error_message = f\"程序运行出错:\\n{traceback.format_exc()}\"\n",
    "        print(error_message)\n",
    "        send_email(f\"48号机{sim}的power程序出错通知\", error_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5113bee-f938-401b-9bc8-cf597e7a9357",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_cores = 100  # GPU 核心数量\n",
    "# cuda_cores = 100  # 可根据实际的 GPU 核心数量或 CPU 线程设置\n",
    "\n",
    "# sim_list = {'my_data_ex7':int(5)}\n",
    "sim_list = {'my_data_ex6': int(p/5),'my_data_ex7': int(8),'my_data_ex8': int(p/5),'my_data_ex9': int(p/5),'my_data_ex10': int(p/5)}\n",
    "for sim, dep in sim_list.items():\n",
    "    resmy = torch.zeros(n_my, 3, 3)\n",
    "    print(sim, dep)\n",
    "    try:\n",
    "        with Parallel(n_jobs=cuda_cores) as parallel:\n",
    "            tmp_results = parallel(       \n",
    "                delayed(run_simulation)(i, n, p, q, m, dep, n_1, n_2, n_3, n_tilde, alpha, getattr(gene_data_Copy1, sim), cuda_cores)\n",
    "                for i in tqdm(range(n_my))\n",
    "            )\n",
    "        results = torch.stack(tmp_results).to('cpu')\n",
    "        del tmp_results\n",
    "        \n",
    "\n",
    "        # results = torch.stack(Parallel(n_jobs=cuda_cores)(delayed(run_simulation)(i, n, p, q, m, dep, n_1, n_2, n_3, n_tilde, alpha, getattr(gene_data, sim), cuda_cores) for i in tqdm(range(n_my))))\n",
    "        res_all = torch.randn(n_my, 3)\n",
    "        res_size = torch.randn(n_my, 3)\n",
    "        res_n = torch.randn(n_my, 3)\n",
    "        for i in range(n_my):\n",
    "            res_all[i, :] = results[i, :, 0]\n",
    "            res_size[i, :] = results[i, :, 1]\n",
    "            res_n[i, :] = results[i, :, 2]\n",
    "            \n",
    "        res_my = torch.mean(res_all, dim=0)\n",
    "        \n",
    "        df1 = pd.DataFrame(res_my)\n",
    "    \n",
    "        dic_path = './ind1_test_m52'\n",
    "        file_path = os.path.join(dic_path, f'result_{sim}2.xlsx')\n",
    "        \n",
    "        # 将DataFrame保存到Excel文件\n",
    "        # df1.to_excel(file_path, index=False, sheet_name='Sheet1')\n",
    "\n",
    "        # 将 DataFrame 保存到 CSV 文件\n",
    "        file_path = os.path.join(dic_path, f'result_{sim}2.csv')\n",
    "        df1.to_csv(file_path, index=False, encoding='utf-8')\n",
    "        \n",
    "        \n",
    "        df2 = pd.DataFrame(res_size)\n",
    "        # file_path2 = os.path.join(dic_path, f'result_{sim}power.xlsx')\n",
    "        file_path2 = os.path.join(dic_path, f'result_{sim}power2.csv')\n",
    "        # 将DataFrame保存到Excel文件\n",
    "        # df2.to_excel(file_path2, index=False, sheet_name='Sheet1')\n",
    "        df2.to_csv(file_path2, index=False, encoding='utf-8')\n",
    "        \n",
    "        df3 = pd.DataFrame(res_n)\n",
    "        # file_path3 = os.path.join(dic_path, f'result_{sim}_n1.xlsx')\n",
    "        file_path3 = os.path.join(dic_path, f'result_{sim}_n2.csv')\n",
    "        \n",
    "        # 将DataFrame保存到Excel文件\n",
    "        # df3.to_excel(file_path2, index=False, sheet_name='Sheet1')\n",
    "        df3.to_csv(file_path3, index=False, encoding='utf-8')\n",
    "        print(res_my)\n",
    "        send_email(f\"48号机{sim}的power程序运行成功\", str(res_my))\n",
    "\n",
    "        del results\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "    except Exception as e:\n",
    "        # 捕获异常并发送邮件\n",
    "        error_message = f\"程序运行出错:\\n{traceback.format_exc()}\"\n",
    "        print(error_message)\n",
    "        send_email(f\"48号机{sim}的power程序出错通知\", error_message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
